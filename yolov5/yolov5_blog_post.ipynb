{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241fcbdc-65d3-49d5-b8f9-63fe79c48bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd ~/yolov5\n",
    "%pip install -r requirements.txt\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d26215-efd0-4824-8aa5-88be1c39c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tqdm\n",
    "%pip install datasets\n",
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a677be-4fd7-4b10-8641-627cecdc914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "def download_dataset():\n",
    "    wider_face = load_dataset('wider_face', split='train')\n",
    "    print(\"Num images in wider_face training set: %i\" % (len(wider_face)))\n",
    "\n",
    "    img = np.array(wider_face[110]['image'], dtype=np.uint8)\n",
    "    faces = wider_face[110]['faces']\n",
    "    bboxes = faces['bbox']\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        rect = patches.Rectangle((bbox[0], bbox[1]),\n",
    "                                 bbox[2], bbox[3],\n",
    "                                 linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return wider_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b16293-03a0-43d3-8c8b-1fd390e42049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "from datasets import IterableDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def convert_to_yolov5_format(\n",
    "    dataset: IterableDataset, \n",
    "    dst_dir: str, \n",
    ") -> None:\n",
    "    Path(os.path.join(dst_dir, \"images\")).mkdir(parents=True, exist_ok=True)\n",
    "    Path(os.path.join(dst_dir, \"labels\")).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        data_point = dataset[i]\n",
    "        pil_img = data_point['image']\n",
    "        label = data_point['faces']\n",
    "        img_filename = str(i) + \".png\"\n",
    "\n",
    "        dst_image_file = os.path.join(dst_dir, \"images/%s\" % (img_filename))\n",
    "        dst_label_file = os.path.join(dst_dir, \"labels/%s\" % (img_filename.replace(\".png\", \".txt\")))\n",
    "        if os.path.exists(dst_label_file):\n",
    "            continue\n",
    "        \n",
    "        class_name = \"face\"  # we're only detecting faces, so these are constants\n",
    "        class_id = 0\n",
    "        width, height = pil_img.size\n",
    "        with open(dst_label_file, \"w\") as wobj:\n",
    "            for bbox in label['bbox']:\n",
    "                x_max = (bbox[0] + bbox[2]) / width\n",
    "                y_max = (bbox[1] + bbox[3]) / height\n",
    "                cx = (bbox[0] + x_max) / 2.0 / width\n",
    "                cy = (bbox[1] + y_max) / 2.0 / height\n",
    "\n",
    "                # output annotation is: class_id, center_x, center_y, box_width, box_height,\n",
    "                # image width and height normalized to (0, 1)\n",
    "                output_line = \"%d %f %f %f %f\\n\" % (class_id, cx, cy, bbox[2]/width, bbox[3]/height)\n",
    "                wobj.write(output_line)\n",
    "        pil_img.save(dst_image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b415e71-4e42-4482-bc1d-e898780fc111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolov5_dataset_yaml(yolo_train_dir: str, yolo_test_dir: str):\n",
    "    yaml_file = \"yolov5/data/wider_face.yaml\"\n",
    "    train_images_dir = os.path.join(yolo_train_dir, \"images\")\n",
    "    val_images_dir = os.path.join(yolo_test_dir, \"images\")\n",
    "\n",
    "    classes = ['Face']\n",
    "    names_str = \"\"\n",
    "    for item in classes:\n",
    "        names_str = names_str + \", \\'%s\\'\" % item\n",
    "    names_str = \"names: [\" + names_str[1:] + \"]\"\n",
    "\n",
    "    with open(yaml_file, \"w\") as wobj:\n",
    "        wobj.write(\"train: %s\\n\" % train_images_dir)\n",
    "        wobj.write(\"val: %s\\n\" % val_images_dir)\n",
    "        wobj.write(\"nc: %d\\n\" % len(classes))\n",
    "        wobj.write(names_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe4f31c-3380-4ab2-928b-bf04a4ad4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_dataset import download_dataset\n",
    "from convert_to_yolov5_format import convert_to_yolov5_format\n",
    "from create_yolov5_dataset_yaml import create_yolov5_dataset_yaml\n",
    "from yolov5.utils.downloads import attempt_download\n",
    "\n",
    "wider_face = download_dataset()\n",
    "\n",
    "yolo_train_dir = \"./yolov5/data/train\"\n",
    "convert_to_yolov5_format(wider_face, yolo_train_dir)\n",
    "\n",
    "yolo_test_dir = \"./yolov5/data/test\"\n",
    "convert_to_yolov5_format(wider_face, yolo_test_dir)\n",
    "\n",
    "create_yolov5_dataset_yaml(yolo_train_dir, yolo_test_dir)\n",
    "\n",
    "attempt_download('weights/yolov5s.pt')\n",
    "attempt_download('weights/yolov5m.pt')\n",
    "attempt_download('weights/yolov5l.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf00468f-08fa-4003-826d-75bfb2df2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node 2 train.py --data data/wider_face.yaml --batch-size 32 --epochs 10 --img-size 768 --project runs/train --name wider_face --weights weights/yolov5s.pt --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd4806-07af-4acf-86e1-fd44097a2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node 2 train.py --data data/wider_face.yaml --batch-size 32 --epochs 10 --img-size 768 --project runs/train --name wider_face --weights weights/yolov5m.pt --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01d37e-e61c-4fe3-980b-6414e2018f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node 2 train.py --data data/wider_face.yaml --batch-size 32 --epochs 10 --img-size 768 --project runs/train --name wider_face --weights weights/yolov5l.pt --device 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
